---
title: "Project_5-Prediction_of_Drinking_Water_Potability"
author: "Tiffany & Fahad"
date: "11/09/2021"
knit:: (function(inputFile, encoding){
  out_dir <- '../output';
  rmarkdown::render(inputFile, encoding=encoding, output_file=file.path(dirname(inputFile), out_dir, 'Week8Assignment.html')) })


output:
  html_document:
    toc: yes
    toc_depth: 5
    code_folding: hide
    theme: cosmo
    highlight: tango
    
  html_notebook: default
---
```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

#The  goals of the project includes the following:
1. Perform exploratory data analysis 
2. Predict the outcome variable with some form of regression 
3. Exploratory data analysis may involve the following
4.Perform univariate distribution analysis for as many variables as possible, confirmed by quantitative metrics that describe the plots
5. Plot grouped density and grouped histogram, to visualize frequency distribution  of outcome variables and other variables in the dataset
6. Plot grouped categorical plots to visualize patterns that may exist in any relationships within the dataset.
7. Conduct bias analysis with a demographic variable if necessary.
8. Build correlation matrix to confirm the magnitude of the correlation coefficient and direction of observed relationships
9. Use the observed correlation relationships to perform some form of regression to predict the outcome variable in one of the following ways.
linear regression 
10. Logistic regression: Forced entry, Hierarchical, Stepwise ( slide 19 week 11 bias and logistic regression )


# Project #5: Drinking Water Potability

## Description:
Context Access to safe drinking water is essential to health, a basic human right, and a component of effective policy for health protection. This is important as a health and development issue at a national, regional, and local level. In some regions, it has been shown that investments in water supply and sanitation can yield a net economic benefit, since the reductions in adverse health effects and health care costs outweigh the costs of undertaking the interventions.

## Null Hypothesis:
There is no relationship between optimal levels of chemical components contained in treated water and portability of consumed water.

## Alternative Hypothesis:
Two or more optimal levels of combined features are cause for making the water not potable.

See if you can find any other trends in the data to predict portability of consumed water or find any clear indications of relationships between the predictors.

## Content:
The drinkingwaterpotability.csv file contains water quality metrics for 3276 different water bodies.
  1. **pH value**: PH is an important parameter in evaluating the acid-base balance of water. It is also the indicator of the acidic or alkaline condition of water status. WHO has recommended the maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52–6.83 which are in the range of WHO standards.
  2. **Hardness**: Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness-producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.
  3. **Solids** (Total dissolved solids - TDS): Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates, etc. These minerals produced an unwanted taste and diluted color in the appearance of water. This is the important parameter for the use of water. The water with a high TDS value indicates that water is highly mineralized. The desirable limit for TDS is 500 mg/l and the maximum limit is 1000 mg/l which is prescribed for drinking purposes.
  4. **Chloramines**: Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg/L or 4 parts per million (ppm)) are considered safe in drinking water.
  5. **Sulfate**: Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg/L). It ranges from 3 to 30 mg/L in most freshwater supplies, although much higher concentrations (1000 mg/L) are found in some geographic locations.
  6. **Conductivity**: Pure water is not a good conductor of electric current rather’s a good insulator. An increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceed 400 μS/cm.
7. **Organic_carbon**: Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA < 2 mg/L as TOC in treated / drinking water, and < 4 mg/Lit in source water which is use for treatment.
  8. **Trihalomethanes**: THMs are chemicals that may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm are considered safe in drinking water.
  9. **Turbidity**: The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of the light-emitting properties of water and the test is used to indicate the quality of waste discharge with respect to the colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.
  10. **Potability**: Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.


```{r load labraries, include=FALSE}

# A function to Install & loading required libraries to compute the project
required_libraries <- c("DBI","paws","shiny", "shinythemes", "shinycssloaders", "dplyr", "ggplot2","ggthemes","DT","stringr","tidyr","dbplyr","DBI","splitstackshape","magrittr","tidyverse","shinyjs","data.table","plotly", "randomForest", "RColorBrewer","scales","caret", "GGally", "corrplot", "skimr", "glue", "janitor", "RPostgres", "devtools","RPostgreSQL", "formattable", "gmodels", "ggbeeswarm", "ppcor","polycor", "Hmisc", "ggm","boot", "e1071", "gridExtra", "wesanderson", "psych", "pastecs", "car","lattice","grid","kableExtra","knitr", "rayshader", "RCurl", "finalfit", "caret", "VIM")

missing_libraries <- required_libraries[!(required_libraries %in%
                                            installed.packages()[,"Package"])]

if(length(missing_libraries)) install.packages(missing_libraries)


#A function to call the above libraries 

libraries <- function(required_libraries){
  for(package in required_libraries){
    
    if(!require(package, character.only = TRUE)){
     
      install.packages(package, dependencies = TRUE)
    
      library(package, character.only = TRUE)
    }
  }
}
libraries(required_libraries)
```

Read dataset and other assets remotely from AWS-S3
```{r}
#AWS environment setup which is not secured but we have it for temporary usage to access AWS resources
# Sys.setenv(
#   AWS_ACCESS_KEY_ID = "AKIA4CSJQNSCJA74HAIJ",
#   AWS_SECRET_ACCESS_KEY = "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",
#   AWS_REGION = "us-east-1")
```

```{r, warning=FALSE, echo=FALSE}
# Create an S3 client, then list the objects within my bucket `my-bucket`.
#s3 <- paws::s3()
#s3$list_objects(Bucket = "usfca-fall2021")
```
```{r, warning=FALSE}
# Connecting to RPostgreSQL
# drv <- dbDriver('PostgreSQL')  
# db <- 'db-instance-hs631'  
# host_db <- 'db-instance-hs631.cllvlwixyq2w.us-east-1.rds.amazonaws.com'  
# db_port <- '5432'  
# db_user <- 'postgres'  
# db_password <- 'postgresDB2021'
# Will continou working on the integration later as not required by the project 
# conn <- dbConnect(drv, dbname=db, host=host_db, port=db_port, user=db_user, password=db_password)
# 
# # Connecting to RPostgres 
# # with the same connection variables without 'drv'
# 
# conn <- dbConnect(RPostgres::Postgres(), dbname = db2, host=host_db, port=db_port, user=db_user, password=db_password)  
# 
```

Read dataset from local machine:
```{r}
#Read dataset from Github
x <- getURL("https://raw.githubusercontent.com/nitieaj/Project_5-Prediction_of_Drinking_Water_Portability/main/data/drinking_water_potability.csv")
dw.potability <- read.csv(text = x)
#dw.potability <- read.csv("./Data/drinking_water_potability.csv", header = TRUE, sep = ",")%>% glimpse()#using glimpse to have a quick look t the variables we have and the dimensions of the dataset

```

We have about 3,275 * 10 dimension dataset 

```{r}
str(dw.potability)
```
```{r Clean names }
library(janitor) #using janitor library to use clean_names function to:
                    #Returns names with only lowercase letters, with _ as a separator
                    #Handles special characters and spaces
                    #Appends numbers to duplicated names
                    #Converts “%” to “percent” to retain meaning

dw.potability <- dw.potability %>% 
  mutate(Potability = as.numeric(Potability)) %>% #convert Int to factor in *Potability* feature
  clean_names() %>% glimpse()

```
#Now, our variables are in lower case which is intutive whhile we're coding 
```{r}
summary(dw.potability)
```

```{r Missing Values}
dw.potability %>%
  summarise_all(~ sum(is.na(.)))
```
#We have three features are missing values and they are orded bellow by the highest NA values:

**sulfate**         = 743 missing values
**ph**              = 490 missing values
**trihalomethanes** = 162 missing values

```{r}
#Created a vector to subset the completed rows in the dataset
completed.df <- dw.potability[complete.cases(dw.potability), ] 
str(completed.df)

# We have only about 2045 completed rows in the dataset 
```
```{r}
#Calling the required libraries for this chunk 
#library(ggplot2) # For vizulization computation
#library(skimr)#which is similar to summary function, but with opinionated in its defaults 
#library(scales)# to converting from data values to perceptual properties
#library(forcats)#to handle categorical variables, variables that have a fixed and known set of possible values. Factors are also helpful for reordering character vectors to improve display


#creating a new variables that filter our dataset by using skim function and show the output as table
skim.dw.pot <- dw.potability %>%  skim() %>%
   filter(n_missing != 0) %>%
   as_tibble() %>%
   mutate(n_missing, skim_variable, complete_rate) %>% #Mutate targeted variables produced by Skim function such as skim_variable, n_missing, complete_rate  to help us with missing rate classification
   mutate(missing_rate = round(abs(complete_rate - 1) * 100, 1)) # by subtracting 1r from the complete_rate feature and times that by 100


skim.dw.pot
```
 
We will visulize the **skim_variable**, **n_missing, mean** as a missing value rate aganist the atrgeted features **sulfate**, **ph**, **trihalomethanes**
```{r Missing Values Insight}
skim.dw.pot %>%
  ggplot(aes(
     x = fct_reorder(skim_variable, n_missing, mean), 
     y = missing_rate,
     fill = skim_variable, #we fill skim_variable and n_missing, and 
     label = paste0(missing_rate, "%")
   )) +
   geom_col(width = .9) +
   geom_text(
     size = 5.5,
     hjust = 2.2,
     vjust = 1.25,
     col = "white"
   ) +
   coord_flip() + theme(aspect.ratio = .4) +
   theme(
     legend.position = "none"
   ) +
   scale_y_continuous(label = label_percent(scale = 1)) +
   scale_fill_manual(values = c("#2D2D2D",
                                "#E69F00",
                                "#CC79A7")) +
   labs(title = "Missing Values Insight", x = "Targeted Features", y = "Frequency of Distrubtion", caption = "Figure 1.1")

```
**sulfate**         = 743 missing values ~ 22.7%
**ph**              = 490 missing values ~ 15%
**trihalomethanes** = 162 missing values ~ 4.9%

```{r}
dw.potability %>%
  dplyr::select(potability) %>%
  count(potability) %>%
  mutate(percent = paste0(round(n / sum(n) * 100), "%"), 2) %>%
  ggplot(aes(
    x = potability,
    y = n,
    label = percent,
    fill = potability
  )) +
  geom_col() +
  geom_text(vjust = - 0.3, color = "#7C4EA8") +
  scale_fill_manual(values = c("#D55E00", "#0072B2")) +
  labs(
    title = "Distribution of the Potable Water",
    x = "Potability Class 0 and 1",
    y = "Distribution Frequency",
    caption = "Figure 1.2"
  )
```
##
#- 1 = **Potable Water**     ~ 61%
#- 0 = **Not Potable Water** ~ 39%

Before we process the function, we need to know the total number of of NA value in the entire dataset

```{r}
#create a new vector to Impute the missing values with the mean which is a naive solution to make this missing values filled  
#Imputation method 1: mean 
mean.df <- dw.potability %>%
  group_by(potability) %>%
  mutate(across(where(is.numeric), ~if_else(is.na(.), mean(., na.rm = T), as.numeric(.)))) %>%
  ungroup()

head(mean.df)


#mean.df 
```
```{r}
#Comparing the dataset with NA values and with mean Imputed NA
p1 <- ggplot(dw.potability, aes(ph)) + 
        geom_histogram(fill = "white", color = "grey30")

p2 <- ggplot(mean.df, aes(ph)) + 
        geom_histogram(fill = "white", color = "grey30") +
        scale_x_log10()

grid.arrange(p1, p2, ncol = 2)
```
# Based on the comparsion between two dataset whihc are the origianl one **dw.potability** and the mean imputed **mean.df**, we observed that **ph** variable as one of the feature that has affected by NA values has a noramal distrubtion, On the other hand,  **ph** as mean imputed has..


```{r}
#Comparing the dataset with NA values and with mean Imputed NA
s1 <- ggplot(dw.potability, aes(sulfate)) + 
        geom_histogram(fill = "white", color = "grey30")

s2 <- ggplot(mean.df, aes(sulfate)) + 
        geom_histogram(fill = "white", color = "grey30") +
        scale_x_log10()

grid.arrange(s1, s2, ncol = 2)
```

#In this following graph shows the areas that affected by NA per each feature/variable and colored by RED
```{r}
dw.potability %>% aggr(combined = TRUE, number = TRUE)
```

# ```{r}
# dw.potability %>%
#   filter(potability == 1 & ph) %>%
#   spineMiss()
# ```

# ```{r}
# dw.potability %>% mosaicMiss(highlight = "potability", plotvars = c("ph", "sulfate"))
# ```


```{r}
factor.df <-dw.potability %>%
  mutate(potability = as.factor(potability)) %>% #convert Int to factor in *Potability* feature
  clean_names() %>% glimpse()

```

```{r}
#Here we test the if those NA values in the targeted variables are MAR or not: we assume that the H_0 is the mean are equal for both potable or not potable water.

#Creating a new vector to manage the NA per those identifed NA features for the future computaion purposes
factor.df2 <- factor.df %>%
  mutate(missing_ph =is.na(ph), missing.sulfate = is.na(sulfate), missing.thms = is.na(trihalomethanes))

#Create a vector  that contain NA when the water potable called **missing_potability**
missing_potability <- factor.df2 %>%
  filter(potability == "1") %>%
  pull(missing_ph, missing.sulfate)

#Create a vector that contain NA values while the water not potable called **missing_not_potable**
missing_not_potable <- factor.df2 %>%
  filter(potability == "0") %>%
  pull(missing_ph, missing.sulfate)

missing_potability_tmh <- factor.df2 %>%
  filter(potability == "1") %>%
  pull(missing.thms)

missing_not_potable_tnh <- factor.df2 %>%
  filter(potability == "0") %>%
  pull(missing.thms)



t.test(missing_potability, missing_not_potable)
t.test(missing_potability_tmh, missing_not_potable_tnh)
```
#The result, .....

```{r}

```

```{r}
set.seed(1)

#Create a new vector to reserve features that have NA values for the future function as needed 
causative <- dw.potability[ , c("ph", "sulfate", "trihalomethanes")]

head(causative)
```
```{r}
#Model.1 to compute the regression for the original dataset 
model_1 <- lm(potability ~ ph + solids + chloramines + sulfate + conductivity + organic_carbon + trihalomethanes + turbidity, data = dw.potability)

summary(model_1)
```
#We observed that after we ran the linear model for the dataset as is inluding th missing data that 1231 observations have been deleted due to the missingness. Therefore it is not what we are looking for but at least we compute it to make the evaluation at the end.

```{r}
#Model.2
model_2 <- lm(potability ~ ph + solids + chloramines + sulfate + conductivity + organic_carbon + trihalomethanes + turbidity, data = mean.df)

summary(model_2)
```

##Part 2 Imputation:

#We assume that the missing values are made randomly, and we do not understand how random that been made from the dtaaset aquiztion. we prefer to enhance the imputation with incorperating two algorthims such as KNN ~ K-nearest neighbors algorithm, however to determine the k value is a challenging part. Therefore, imputation on the a similar value is better than the entire dataset. Hence, we proposed the follwoing approache to enhance the imputation perfermoance and bring the high imputation accuracy:
1. Mean imputation 

2. We prop sed KI algorithm which is a hybrid missing data by using K-nearest neighbors algorithm along with iterative imputation algorithm and the global correlation structure among the selected value. However, It is not the optimal solution for the large scale dataset. 

3. After the KI has been proceed, the will propose the FCKI algorithm which is similar to Euclidean distance measure to enhance the KI algorthim because FCKI combine fuzzy c-mean clustering, k-nearest neighbor algorithm, and iterative imputation algorithms by imputing the missing values in the dataset where the c-mean has been selected because the the missing value might belong a multiple clusters at the the same time.

MAR and MCAR and MNAR to figure out which imputation methos are optimal for the NA values 

We have created the function codes in Python for the above methods and will make it in R as well.

```{r}
MAR <- function(my,start_row,start_col,mdp){
  numob = len(my.index)
  numvar= len(my.columns)
  allcells=numob*numvar
  nV_Missed = 1395
  nV_causatives = 3
  mdp = mdp / nV_causatives
  
  
}
```
